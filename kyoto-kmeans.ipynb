{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kyoto2006+ データセットを題材にした K-means を用いたクラスタリングによる予測モデルの生成と評価\n",
    "\n",
    "### 準備とデータの読み込み\n",
    "必要なパッケージを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import patch_sklearn\n",
    "# patch_sklearn()\n",
    "import pandas\n",
    "import glob\n",
    "from time import time\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kyoto2006+ データセットは CSV 形式でデータが格納されており、それを表形式に変換する。変換後のファイルの各列の名前とデータのタイプの順をここで指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = [\n",
    "    [\"duration\", \"float32\"],\n",
    "    [\"service\", \"object\"],\n",
    "    [\"source_bytes\", \"uint32\"],\n",
    "    [\"destination_bytes\", \"uint32\"],\n",
    "    [\"count\", \"uint32\"],\n",
    "    [\"same_srv_rate\", \"float32\"],\n",
    "    [\"serror_rate\", \"float32\"],\n",
    "    [\"srv_serror_rate\", \"float32\"],\n",
    "    [\"dst_host_count\", \"uint32\"],\n",
    "    [\"dst_host_srv_count\", \"uint32\"],\n",
    "    [\"dst_host_same_src_port_rate\", \"float32\"],\n",
    "    [\"dst_host_serror_rate\", \"float32\"],\n",
    "    [\"dst_host_srv_serror_rate\", \"float32\"],\n",
    "    [\"flag\", \"object\"],\n",
    "    [\"ids_detection\", \"object\"],\n",
    "    [\"malware_detection\", \"object\"],\n",
    "    [\"ashula_detection\", \"object\"],\n",
    "    [\"label\", \"int8\"],\n",
    "    [\"source_ip_address\", \"object\"],\n",
    "    [\"source_port_number\", \"uint16\"],\n",
    "    [\"destination_ip_address\", \"object\"],\n",
    "    [\"destination_port_number\", \"uint16\"],\n",
    "    [\"start_time\", \"object\"],\n",
    "    [\"protocol\", \"object\"]\n",
    "]\n",
    "column_names = [i[0] for i in column]\n",
    "column_types = { i[0]: i[1] for i in column}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを読み込む。時間の短縮のため、2015年2月分のみを用いて演習の手順を説明する。\n",
    "成果発表では、できるだけデータセット全体を用いて評価してみること。\n",
    "\n",
    "今回はデータ分析のためのツールである Pandas (https://pandas.pydata.org/) を利用する。\n",
    "\n",
    "`read_csv` はデータ間がカンマで区切られた txt ファイルからデータを読み込む API である。\n",
    "第1引数はファイルのパス、`sep`は区切り文字の指定、`header`はtxtファイルの中で列名が入っている行番号、`names`は列名のリストを指定する。CSVファイルには列名は入っていないので `None` を、`names` は `column` のリストを利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015/02の各日データがあるtxtファイルのパスを配列として取得\n",
    "files = glob.glob(\"./dataset/kyoto2006plus/Kyoto2016/2015/02/201502*.txt\")\n",
    "# 時系列順にソートする\n",
    "files.sort()\n",
    "# 各日データを結合して一つのデータセットとして読み込む\n",
    "kyoto_data = pandas.concat([pandas.read_csv(x, sep='\\t', header=None, names=column_names, dtype=column_types) for x in files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの数や平均、分散などの性質を確認するには、`describe` メソッドを利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>source_bytes</th>\n",
       "      <th>destination_bytes</th>\n",
       "      <th>count</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>label</th>\n",
       "      <th>source_port_number</th>\n",
       "      <th>destination_port_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.317268e+00</td>\n",
       "      <td>5.492566e+04</td>\n",
       "      <td>2.175131e+03</td>\n",
       "      <td>5.175024e+00</td>\n",
       "      <td>4.744613e-01</td>\n",
       "      <td>4.152513e-02</td>\n",
       "      <td>4.192815e-01</td>\n",
       "      <td>3.506128e+01</td>\n",
       "      <td>4.014791e+01</td>\n",
       "      <td>2.828774e-02</td>\n",
       "      <td>8.570371e-02</td>\n",
       "      <td>1.340752e-01</td>\n",
       "      <td>-9.081160e-01</td>\n",
       "      <td>3.344987e+04</td>\n",
       "      <td>2.309937e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.953889e+01</td>\n",
       "      <td>8.052808e+06</td>\n",
       "      <td>1.331901e+06</td>\n",
       "      <td>1.023963e+01</td>\n",
       "      <td>4.968409e-01</td>\n",
       "      <td>1.955620e-01</td>\n",
       "      <td>4.526754e-01</td>\n",
       "      <td>4.195258e+01</td>\n",
       "      <td>4.327172e+01</td>\n",
       "      <td>1.617517e-01</td>\n",
       "      <td>2.684495e-01</td>\n",
       "      <td>3.284109e-01</td>\n",
       "      <td>4.189721e-01</td>\n",
       "      <td>2.062878e+04</td>\n",
       "      <td>7.910031e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.220000e+04</td>\n",
       "      <td>2.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.210000e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>3.795400e+04</td>\n",
       "      <td>5.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.435795e+00</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>1.180000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>5.122700e+04</td>\n",
       "      <td>4.450000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.392452e+04</td>\n",
       "      <td>2.121764e+09</td>\n",
       "      <td>1.583454e+09</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration  source_bytes  destination_bytes         count  \\\n",
       "count  7.875764e+06  7.875764e+06       7.875764e+06  7.875764e+06   \n",
       "mean   1.317268e+00  5.492566e+04       2.175131e+03  5.175024e+00   \n",
       "std    7.953889e+01  8.052808e+06       1.331901e+06  1.023963e+01   \n",
       "min    0.000000e+00  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "50%    4.210000e-04  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "75%    1.435795e+00  6.500000e+01       1.180000e+02  4.000000e+00   \n",
       "max    8.392452e+04  2.121764e+09       1.583454e+09  1.000000e+02   \n",
       "\n",
       "       same_srv_rate   serror_rate  srv_serror_rate  dst_host_count  \\\n",
       "count   7.875764e+06  7.875764e+06     7.875764e+06    7.875764e+06   \n",
       "mean    4.744613e-01  4.152513e-02     4.192815e-01    3.506128e+01   \n",
       "std     4.968409e-01  1.955620e-01     4.526754e-01    4.195258e+01   \n",
       "min     0.000000e+00  0.000000e+00     0.000000e+00    0.000000e+00   \n",
       "25%     0.000000e+00  0.000000e+00     0.000000e+00    0.000000e+00   \n",
       "50%     0.000000e+00  0.000000e+00     3.000000e-02    1.100000e+01   \n",
       "75%     1.000000e+00  0.000000e+00     1.000000e+00    9.200000e+01   \n",
       "max     1.000000e+00  1.000000e+00     1.000000e+00    1.000000e+02   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_src_port_rate  dst_host_serror_rate  \\\n",
       "count        7.875764e+06                 7.875764e+06          7.875764e+06   \n",
       "mean         4.014791e+01                 2.828774e-02          8.570371e-02   \n",
       "std          4.327172e+01                 1.617517e-01          2.684495e-01   \n",
       "min          0.000000e+00                 0.000000e+00          0.000000e+00   \n",
       "25%          0.000000e+00                 0.000000e+00          0.000000e+00   \n",
       "50%          1.600000e+01                 0.000000e+00          0.000000e+00   \n",
       "75%          9.600000e+01                 0.000000e+00          0.000000e+00   \n",
       "max          1.000000e+02                 1.000000e+00          1.000000e+00   \n",
       "\n",
       "       dst_host_srv_serror_rate         label  source_port_number  \\\n",
       "count              7.875764e+06  7.875764e+06        7.875764e+06   \n",
       "mean               1.340752e-01 -9.081160e-01        3.344987e+04   \n",
       "std                3.284109e-01  4.189721e-01        2.062878e+04   \n",
       "min                0.000000e+00 -2.000000e+00        0.000000e+00   \n",
       "25%                0.000000e+00 -1.000000e+00        1.220000e+04   \n",
       "50%                0.000000e+00 -1.000000e+00        3.795400e+04   \n",
       "75%                0.000000e+00 -1.000000e+00        5.122700e+04   \n",
       "max                1.000000e+00  1.000000e+00        6.553500e+04   \n",
       "\n",
       "       destination_port_number  \n",
       "count             7.875764e+06  \n",
       "mean              2.309937e+03  \n",
       "std               7.910031e+03  \n",
       "min               0.000000e+00  \n",
       "25%               2.300000e+01  \n",
       "50%               5.300000e+01  \n",
       "75%               4.450000e+02  \n",
       "max               6.553500e+04  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kyoto_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それぞれのフローが攻撃かどうかは \"label\" 列に入っている。\n",
    "\n",
    "1は正常な通信、その他は不正な通信であり、不正な通信はいくつかの種類(-1:known attack, -2:unknown attack)に分かれている。\n",
    "\n",
    "label の種類数やそれぞれの label の数を表示するには、値とその値を持つデータの数を出力する `value_counts()` メソッドを利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "-1    7513100\n",
       " 1     362107\n",
       "-2        557\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kyoto_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means の適用\n",
    "データセットの中には、クラスタリングにそのまま用いることは困難な（そのままでは距離を定義することができない）データがある。\n",
    "例えば、protocol はプロトコルの種別が入っており、量ではないので、異なる種別間の距離は何らかの方法で定義する必要がある。\n",
    "そのため、クラスタリングを実行する前に、データに前処理を施す必要がある。\n",
    "\n",
    "今回は、そのようなデータを除いてクラスタリングを行う。クラスタリングに利用する列は以下とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_features = [\n",
    "    \"duration\", \"source_bytes\", \"destination_bytes\", \n",
    " \"count\", \"same_srv_rate\", \"serror_rate\", \"srv_serror_rate\",\"dst_host_count\",\n",
    "  \"dst_host_srv_count\", \"dst_host_same_src_port_rate\", \"dst_host_serror_rate\",\n",
    "  \"dst_host_srv_serror_rate\", \"source_port_number\", \"destination_port_number\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この列のみを抽出する。\n",
    "また、protocol 種別のような種類を示す column はダミー変数にするとよい。\n",
    "cluster_features を抽出し、protocol をダミー変数として追加した `cluster_data` を取得する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = pandas.get_dummies(kyoto_data[cluster_features + ['protocol']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "のようにする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それぞれの列の値が取り得る値域は大きく異なるため、値域の幅が大きいものに結果が大きく影響してしまう可能性がある。そこで、`sklearn.preprocessing.MinMaxScaler` を利用し、最小値を0、最大値を1に正規化する。\n",
    "\n",
    "具体的には、MinMaxScaler の `fit_transform` メソッドを利用する。\n",
    "\n",
    "この返り値は numpy の array なので、Pandas で扱うには Pandas の DataFrame に戻す必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = pandas.DataFrame(MinMaxScaler().fit_transform(cluster_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`describe` メソッドで最小値が0, 最大値が1になっていることが確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.569586e-05</td>\n",
       "      <td>2.588679e-05</td>\n",
       "      <td>1.373662e-06</td>\n",
       "      <td>5.175024e-02</td>\n",
       "      <td>4.744610e-01</td>\n",
       "      <td>4.152513e-02</td>\n",
       "      <td>4.192817e-01</td>\n",
       "      <td>3.506128e-01</td>\n",
       "      <td>4.014791e-01</td>\n",
       "      <td>2.828774e-02</td>\n",
       "      <td>8.570375e-02</td>\n",
       "      <td>1.340752e-01</td>\n",
       "      <td>5.104123e-01</td>\n",
       "      <td>3.524738e-02</td>\n",
       "      <td>1.113289e-02</td>\n",
       "      <td>6.184246e-01</td>\n",
       "      <td>3.704425e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.477432e-04</td>\n",
       "      <td>3.795336e-03</td>\n",
       "      <td>8.411361e-04</td>\n",
       "      <td>1.023963e-01</td>\n",
       "      <td>4.968409e-01</td>\n",
       "      <td>1.955620e-01</td>\n",
       "      <td>4.526754e-01</td>\n",
       "      <td>4.195258e-01</td>\n",
       "      <td>4.327172e-01</td>\n",
       "      <td>1.617517e-01</td>\n",
       "      <td>2.684495e-01</td>\n",
       "      <td>3.284109e-01</td>\n",
       "      <td>3.147750e-01</td>\n",
       "      <td>1.206993e-01</td>\n",
       "      <td>1.049235e-01</td>\n",
       "      <td>4.857732e-01</td>\n",
       "      <td>4.829233e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.861601e-01</td>\n",
       "      <td>3.509575e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.016413e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>1.100000e-01</td>\n",
       "      <td>1.600000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.791409e-01</td>\n",
       "      <td>8.087282e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.710817e-05</td>\n",
       "      <td>3.063489e-08</td>\n",
       "      <td>7.452062e-08</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.200000e-01</td>\n",
       "      <td>9.600000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.816739e-01</td>\n",
       "      <td>6.790265e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06   \n",
       "mean   1.569586e-05  2.588679e-05  1.373662e-06  5.175024e-02  4.744610e-01   \n",
       "std    9.477432e-04  3.795336e-03  8.411361e-04  1.023963e-01  4.968409e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    5.016413e-09  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    1.710817e-05  3.063489e-08  7.452062e-08  4.000000e-02  1.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06   \n",
       "mean   4.152513e-02  4.192817e-01  3.506128e-01  4.014791e-01  2.828774e-02   \n",
       "std    1.955620e-01  4.526754e-01  4.195258e-01  4.327172e-01  1.617517e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  3.000000e-02  1.100000e-01  1.600000e-01  0.000000e+00   \n",
       "75%    0.000000e+00  1.000000e+00  9.200000e-01  9.600000e-01  0.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06   \n",
       "mean   8.570375e-02  1.340752e-01  5.104123e-01  3.524738e-02  1.113289e-02   \n",
       "std    2.684495e-01  3.284109e-01  3.147750e-01  1.206993e-01  1.049235e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  1.861601e-01  3.509575e-04  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  5.791409e-01  8.087282e-04  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  7.816739e-01  6.790265e-03  0.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                 15            16  \n",
       "count  7.875764e+06  7.875764e+06  \n",
       "mean   6.184246e-01  3.704425e-01  \n",
       "std    4.857732e-01  4.829233e-01  \n",
       "min    0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  \n",
       "50%    1.000000e+00  0.000000e+00  \n",
       "75%    1.000000e+00  1.000000e+00  \n",
       "max    1.000000e+00  1.000000e+00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータに対して、K-means を実行する。`n_clusters` はクラスタ数を指定する。ここでは 30 を指定する。データ量の関係から Mini Batch K-means を利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ansai/.pyenv/versions/3.9.6/envs/security-practice/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 30\n",
    "km = MiniBatchKMeans(n_clusters=n_clusters, batch_size=10000).fit(cluster_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果の確認\n",
    "元のデータのラベルを参考に、各クラスタに属するデータのラベルの種類や数を見ていく。\n",
    "\n",
    "元々のデータセットの各行がどのクラスタに分類されたかは、`km.labels_` の配列に入っている。\n",
    "\n",
    "データセットの各行のラベルをクラスタ毎に類別する。類別結果を`label_names`に格納する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [ kyoto_data['label'][km.labels_ == cluster_index] for cluster_index in range(n_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "-1    569734\n",
      " 1       899\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 1\n",
      "-1    969836\n",
      " 1     67156\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 2\n",
      "-1    120387\n",
      "-2         3\n",
      " 1         2\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 3\n",
      "-1    782465\n",
      " 1     58060\n",
      "-2       250\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 4\n",
      "-1    441941\n",
      " 1       768\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 5\n",
      "-1    165975\n",
      " 1     24738\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 6\n",
      "-1    342069\n",
      " 1      9925\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 7\n",
      "-1    23723\n",
      " 1      145\n",
      "-2        3\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 8\n",
      "-1    72887\n",
      " 1     6533\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 9\n",
      "-1    142290\n",
      "-2        48\n",
      " 1        20\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 10\n",
      "-1    155723\n",
      " 1       529\n",
      "-2         2\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 11\n",
      "-1    73755\n",
      " 1    23452\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 12\n",
      "-1    77156\n",
      " 1    10512\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 13\n",
      "-1    146233\n",
      " 1     45158\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 14\n",
      "-1    67190\n",
      " 1      234\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 15\n",
      "-1    977267\n",
      " 1     13589\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 16\n",
      "-1    162236\n",
      " 1      2441\n",
      "-2         3\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 17\n",
      "-1    53406\n",
      " 1      283\n",
      "-2       13\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 18\n",
      "-1    164170\n",
      " 1       769\n",
      "-2         1\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 19\n",
      "-1    232056\n",
      "-2         2\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 20\n",
      "-1    111126\n",
      " 1       559\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 21\n",
      "-1    825388\n",
      " 1      1799\n",
      "-2        23\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 22\n",
      "-1    38589\n",
      " 1      201\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 23\n",
      "-1    258414\n",
      " 1      2168\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 24\n",
      "-1    49587\n",
      "-2      209\n",
      " 1        1\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 25\n",
      "-1    265208\n",
      " 1      1611\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 26\n",
      "-1    86885\n",
      " 1    79503\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 27\n",
      "-1    39631\n",
      " 1       67\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 28\n",
      "-1    33796\n",
      " 1    10985\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Cluster 29\n",
      "-1    63977\n",
      "Name: label, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, val in enumerate(label_names):\n",
    "    print(\"Cluster {}\".format(idx))\n",
    "    print(val.value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば、ここから各クラスタに含まれる正常な通信と不正な通信の割合を見ていくなら、以下のようにすればよい。normal と attack が綺麗に分かれているほどよい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "normal = 0.14022069807761506, attack = 0.8597793019223849, total = 183418\n",
      "Cluster 1\n",
      "normal = 0.0019365397724432835, attack = 0.9980634602275568, total = 940337\n",
      "Cluster 2\n",
      "normal = 0.06979320654984966, attack = 0.9302067934501503, total = 899013\n",
      "Cluster 3\n",
      "normal = 0.0680232353458898, attack = 0.9319767646541102, total = 852150\n",
      "Cluster 4\n",
      "normal = 0.0, attack = 1.0, total = 232933\n",
      "Cluster 5\n",
      "normal = 0.00409011469944633, attack = 0.9959098853005537, total = 136182\n",
      "Cluster 6\n",
      "normal = 0.0022064690220265897, attack = 0.9977935309779734, total = 892376\n",
      "Cluster 7\n",
      "normal = 0.025191064008567826, attack = 0.9748089359914321, total = 411773\n",
      "Cluster 8\n",
      "normal = 0.24241293918953924, attack = 0.7575870608104608, total = 96513\n",
      "Cluster 9\n",
      "normal = 0.00029693647512961667, attack = 0.9997030635248704, total = 255947\n",
      "Cluster 10\n",
      "normal = 0.022631243850205474, attack = 0.9773687561497946, total = 310986\n",
      "Cluster 11\n",
      "normal = 0.1199069215677328, attack = 0.8800930784322671, total = 87668\n",
      "Cluster 12\n",
      "normal = 0.0030163576559434782, attack = 0.9969836423440566, total = 135594\n",
      "Cluster 13\n",
      "normal = 0.20608437816635689, attack = 0.7939156218336431, total = 160871\n",
      "Cluster 14\n",
      "normal = 0.005753720225354042, attack = 0.994246279774646, total = 58397\n",
      "Cluster 15\n",
      "normal = 0.001741632591246403, attack = 0.9982583674087536, total = 39618\n",
      "Cluster 16\n",
      "normal = 0.006821103061462958, attack = 0.993178896938537, total = 68464\n",
      "Cluster 17\n",
      "normal = 0.02050707789099364, attack = 0.9794929221090064, total = 350952\n",
      "Cluster 18\n",
      "normal = 1.529940944279551e-05, attack = 0.9999847005905572, total = 130724\n",
      "Cluster 19\n",
      "normal = 0.005428388062894427, attack = 0.9945716119371055, total = 37396\n",
      "Cluster 20\n",
      "normal = 0.016827871017801605, attack = 0.9831721289821984, total = 783581\n",
      "Cluster 21\n",
      "normal = 0.008064418770296863, attack = 0.9919355812297032, total = 248499\n",
      "Cluster 22\n",
      "normal = 0.006203322042198914, attack = 0.9937966779578011, total = 49006\n",
      "Cluster 23\n",
      "normal = 0.0027366192924100394, attack = 0.9972633807075899, total = 66140\n",
      "Cluster 24\n",
      "normal = 0.006421684206490693, attack = 0.9935783157935093, total = 52167\n",
      "Cluster 25\n",
      "normal = 0.003740673727865986, attack = 0.996259326272134, total = 98378\n",
      "Cluster 26\n",
      "normal = 0.257740249296341, attack = 0.742259750703659, total = 42279\n",
      "Cluster 27\n",
      "normal = 0.47858551529960436, attack = 0.5214144847003956, total = 161246\n",
      "Cluster 28\n",
      "normal = 0.0021426716301618906, attack = 0.9978573283698381, total = 46204\n",
      "Cluster 29\n",
      "normal = 0.2886990969500767, attack = 0.7113009030499233, total = 46952\n"
     ]
    }
   ],
   "source": [
    "for idx, val in enumerate(label_names):\n",
    "    print(\"Cluster {}\".format(idx))\n",
    "    attack = 0\n",
    "    normal = 0\n",
    "    for label in val:\n",
    "        if label == 1:\n",
    "            normal += 1\n",
    "        else:\n",
    "            attack += 1\n",
    "    print(\"normal = {}, attack = {}, total = {}\".format(normal/(normal+attack), attack/(normal+attack), normal+attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラスタリングされた結果の評価尺度は様々なものがあるが、クラスタの中心とそのクラスタに分類されたデータとの距離の和は `inertia_` 属性でアクセスできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830938.5553672388"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検証\n",
    "本演習の目的は、あるフローが与えられた時に正規の通信か不正な通信かを予測する予測モデルを過去のトラフィックデータから生成することである。\n",
    "\n",
    "ここでは、過去の通信から現在の通信が正規なものか不正なものかを判断するので、時間的な順序を考慮し、データセットを分割し、過去のトラフィックデータで学習させたもので新しい通信の予測がどの程度正しいかどうかの検証を行う。\n",
    "\n",
    "まずはデータセットのラベルを attack と normal の2種類に変換する関数を用意する。`get_label`関数は、あるクラスタに属するデータのラベルが配列として入力され、その配列のうち正常(1)と攻撃(-1,-2)どちらが多いか判断し、その結果を出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(cluster):\n",
    "    normal = 0\n",
    "    attack = 0\n",
    "    ret = \"unknown.\"\n",
    "    for label in cluster:\n",
    "        if label == 1:\n",
    "            normal += 1\n",
    "        else:\n",
    "            attack += 1\n",
    "    if normal > attack:\n",
    "        ret = 'normal.'\n",
    "    elif normal < attack:\n",
    "        ret = 'attack.'\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを4分割し、過去の3セットで学習し、それより新しい1セットの予測を検証する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = int(len(cluster_data)/4)\n",
    "learn_data = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "過去の3セットでクラスタリングを行い、各クラスタに normal または attack のラベルをつける。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ansai/.pyenv/versions/3.9.6/envs/security-practice/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "km.fit(cluster_data[0:data_len * learn_data])\n",
    "label_names = [ get_label(kyoto_data['label'][:data_len * learn_data][(km.labels_ == cluster_index)]) for cluster_index in range(n_clusters)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習に用いなかったデータの予測を行う。\n",
    "predにはどのクラスタに属するかの値が入る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = km.predict(cluster_data[data_len * learn_data:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測が正しいかどうかを検証する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success = 1937256, failed = 31685, normal = 31685, attack = 1937256, unknown = 0\n",
      "TP = 0, FN = 31685, FP = 0, TN = 1937256\n"
     ]
    }
   ],
   "source": [
    "success = 0\n",
    "fail = 0\n",
    "normal = 0\n",
    "attack = 0\n",
    "# correct_predict\n",
    "tp = 0 # 真陽性(true positive) ：　正しく陽性と判定\n",
    "fn = 0 # 偽陰性(false negative)　：　本当は陽性なのに、陰性と判定\n",
    "fp = 0 #偽陽性(false positive)　：　本当は陰性なのに、陽性と判定\n",
    "tn = 0 #真陰性(true negative)　：　正しく陰性と判定\n",
    "\n",
    "for i in range(data_len * (4 - learn_data)):\n",
    "    predicate = label_names[pred[i]]\n",
    "    correct = get_label([kyoto_data['label'][data_len * learn_data + i]])\n",
    "    if predicate == correct: # 正しく判定\n",
    "        success += 1\n",
    "        # 真陽性か真陰性か\n",
    "        if correct == 'normal.':\n",
    "            tp += 1 # 正しく陽性と判定\n",
    "        elif correct == 'attack.':\n",
    "            tn += 1 # 正しく陰性と判定\n",
    "    else: # 誤った判定\n",
    "        fail += 1\n",
    "        # 偽陰性か偽陽性か\n",
    "        if correct == 'normal.':\n",
    "            fn += 1# 誤って陰性と判定\n",
    "        elif correct == 'attack.':\n",
    "            fp += 1# 誤って陽性と判定\n",
    "    # 正常通信と攻撃通信の数を計算\n",
    "    if correct == 'normal.':\n",
    "        normal += 1\n",
    "    elif correct == 'attack.':\n",
    "        attack += 1\n",
    "\n",
    "print(\"success = {}, failed = {}, normal = {}, attack = {}, unknown = {}\".format(success, fail, normal, attack, success + fail - normal - attack))\n",
    "print(\"TP = {}, FN = {}, FP = {}, TN = {}\".format(tp, fn, fp, tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、予測が正しいかの検証は以下のプログラムを実行しても確認できる。混同行列と呼ばれる2×2行列の各成分を見ることで、TPの値などを調べられる。\n",
    "混合行列である`confusion_matrix`から各成分の値を取り出す際は、`ravel()`メソッドを用いれば良い。\n",
    "\n",
    "\n",
    "$$\n",
    "    ConfusionMatrix = \\left[\\begin{array}{c|c} TN & FP \\\\ \\hline FN & TP \\\\ \\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1937256       0]\n",
      " [  31685       0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "correct = kyoto_data['label'][data_len * learn_data:].map(lambda x: 'normal.' if x == 1 else 'attack.')\n",
    "predicate = pandas.Series(pred).map(lambda x: label_names[x])\n",
    "\n",
    "c_matrix = confusion_matrix(correct, predicate)\n",
    "tn, fp, fn, tp = c_matrix.ravel()\n",
    "\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類問題のモデルを評価する際に使われる代表的な評価指標\n",
    "1. 正確度(Accuracy): 推定した値と真の値が一致した割合\n",
    "$$ \\frac{TP + TN}{TP + FP + TN + FN} = \\frac{正しく判定}{全体}$$\n",
    "    - FPとFNの重要度について考慮しなくていい場合に使える\n",
    "2. 適合率(Precision): モデルが陽性と判定した中で、真に陽性だった割合 \n",
    "$$ \\frac{TP}{TP + FP} = \\frac{真に陽性}{陽性と判定} $$\n",
    "    - 明らかに陽性と分かりやすいものだけを見つけたい時\n",
    "    - FNが発生することを許容できるようなケースで、それでもなおFPがあっては困る場合に使える\n",
    "3. 再現率(Recall): 真に陽性だったものの中で、モデルが陽性と判定した割合 \n",
    "$$ \\frac{TP}{TP + FN} = \\frac{陽性と判定}{真に陽性} $$\n",
    "    - 怪しいものを全て見つけ出したい時\n",
    "    - FPが発生することを許容できるケースで、それでもなおFNがあっては困る場合に使える。\n",
    "4. F-値(F-measure): 適合率と再現率の調和平均\n",
    "$$ \\frac{2}{\\frac{1}{Precision} + \\frac{1}{Recall}} =  \\frac{2 * (Precision * Recall)}{Precision + Recall} $$\n",
    "    - 正確度と違い、陽性と陰性の出現度合いが極端に異なる場合でも、評価しやすい\n",
    "5. 特異度(Specificity): 実際に陰性だったものの中で、モデルが陽性と判断した割合\n",
    "$$ \\frac{TN}{FP + TN} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9839075929649492\n",
      "Recall = 0.0\n",
      "F-measure = 0.0\n",
      "Specificity = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = {}\" .format((tp + tn) / (tp + tn + fp + fn) ))\n",
    "if tp > 0 or fp > 0:\n",
    "    print(\"Precision = {}\" .format( tp/ (tp + fp) ))\n",
    "print(\"Recall = {}\" .format(tp/ (tp + fn) ))\n",
    "print(\"F-measure = {}\" .format(2 * tp / (2 * tp + fn + fp ) ))\n",
    "print(\"Specificity = {}\" .format(tn/(fp + tn) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際には、学習および検証に使うデータの時期を少しずつ変更して何度も評価が行われる。\n",
    "例えば、利用するデータセットを n 週間分 (n = 1,...) ずらして同様の評価を行うなどが考えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改良に向けたアイデア\n",
    "以下はあくまでも例であり、各グループでアイデアを出し合って様々な改良を試すことを期待している。\n",
    "- 結果を見てわかるように、データセットのlabelには大きな偏りがあり（攻撃トラフィックが圧倒的に多い）、上の手順ではこれを考慮していないため、ほぼ全ての通信が攻撃と判定されている。これでは現実的には役に立たない。そこで、不均衡なデータを扱うための枠組み（サンプリングなど）を適用してみる。\n",
    "  - 例えば、攻撃トラフィックのみを K-means でクラスタリングし、各クラスタから少数のトラフィックだけサンプリングしてみるなど。\n",
    "- 通信のパターンはサービス (http, ftp など) によって異なると考えられるため、サービスごとに学習させてみる。\n",
    "- ダミー変数にするフィールドを追加・削除してみる。あるいは、一部のフィールドを削除してみる。\n",
    "- 教師あり学習 (SVM など) を利用してみる。SVMを利用した例は kyoto2006plus_svm_example.ipynb にある (TA提供)。\n",
    "- 正常な通信と攻撃の通信ではなく、既知の攻撃か未知の攻撃かを予測する。\n",
    "\n",
    "なお、攻撃者は検知システムを迂回するために攻撃手法に少しずつ変更を加えてくることが想定される。検知システムはそれらの変更に頑健であることが求められる。例えば、IPアドレスをベースに検知することは不適切である一方、攻撃のホストの振る舞いを学習するために、同一のホストが行なった複数の通信を紐づけるためのkeyとしてIPアドレスを用いることは問題ないであろう。これは、攻撃に利用するIPアドレスを変更することは容易であるが、攻撃による通信の振る舞いを変更することは (おそらく) 難しいためである。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
