{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kyoto2006+ データセットを題材にした SVM を用いたの予測モデルの生成と評価\n",
    "\n",
    "### 準備とデータの読み込み\n",
    "\n",
    "K-means の時と同様に必要なパッケージを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearnex import patch_sklearn\n",
    "# patch_sklearn()\n",
    "import pandas\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kyoto2006+ データセットは CSV 形式でデータが格納されており、それを表形式に変換する。変換後のファイルの各列の名前の順をここで指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = [\n",
    "    [\"duration\", \"float32\"],\n",
    "    [\"service\", \"object\"],\n",
    "    [\"source_bytes\", \"uint32\"],\n",
    "    [\"destination_bytes\", \"uint32\"],\n",
    "    [\"count\", \"uint32\"],\n",
    "    [\"same_srv_rate\", \"float32\"],\n",
    "    [\"serror_rate\", \"float32\"],\n",
    "    [\"srv_serror_rate\", \"float32\"],\n",
    "    [\"dst_host_count\", \"uint32\"],\n",
    "    [\"dst_host_srv_count\", \"uint32\"],\n",
    "    [\"dst_host_same_src_port_rate\", \"float32\"],\n",
    "    [\"dst_host_serror_rate\", \"float32\"],\n",
    "    [\"dst_host_srv_serror_rate\", \"float32\"],\n",
    "    [\"flag\", \"object\"],\n",
    "    [\"ids_detection\", \"object\"],\n",
    "    [\"malware_detection\", \"object\"],\n",
    "    [\"ashula_detection\", \"object\"],\n",
    "    [\"label\", \"int8\"],\n",
    "    [\"source_ip_address\", \"object\"],\n",
    "    [\"source_port_number\", \"uint16\"],\n",
    "    [\"destination_ip_address\", \"object\"],\n",
    "    [\"destination_port_number\", \"uint16\"],\n",
    "    [\"start_time\", \"object\"],\n",
    "    [\"protocol\", \"object\"]\n",
    "]\n",
    "column_names = [i[0] for i in column]\n",
    "column_types = {i[0]: i[1] for i in column}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを読み込む。時間の短縮のため、2015年2月分のみを用いて演習の手順を説明する。\n",
    "成果発表では、できるだけデータセット全体を用いて評価してみること。\n",
    "\n",
    "今回はデータ分析のためのツールである Pandas (https://pandas.pydata.org/) を利用する。\n",
    "\n",
    "`read_csv` はデータ間がカンマで区切られた txt ファイルからデータを読み込む API である。\n",
    "第1引数はファイルのパス、`sep`は区切り文字の指定、`header`はtxtファイルの中で列名が入っている行番号、`names`は列名のリストを指定する。CSVファイルには列名は入っていないので `None` を、`names` は `column` のリストを利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"./dataset/kyoto2006plus/Kyoto2016/2015/02/201502*.txt\")\n",
    "files.sort() # ファイルを時系列順に整列\n",
    "kyoto_data = pandas.concat([pandas.read_csv(x, sep='\\t', header=None, names=column_names, dtype=column_types) for x in files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの数や平均、分散などの性質を確認するには、`describe` メソッドを利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>source_bytes</th>\n",
       "      <th>destination_bytes</th>\n",
       "      <th>count</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>label</th>\n",
       "      <th>source_port_number</th>\n",
       "      <th>destination_port_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.317268e+00</td>\n",
       "      <td>5.492566e+04</td>\n",
       "      <td>2.175131e+03</td>\n",
       "      <td>5.175024e+00</td>\n",
       "      <td>4.744613e-01</td>\n",
       "      <td>4.152513e-02</td>\n",
       "      <td>4.192815e-01</td>\n",
       "      <td>3.506128e+01</td>\n",
       "      <td>4.014791e+01</td>\n",
       "      <td>2.828774e-02</td>\n",
       "      <td>8.570371e-02</td>\n",
       "      <td>1.340752e-01</td>\n",
       "      <td>-9.081160e-01</td>\n",
       "      <td>3.344987e+04</td>\n",
       "      <td>2.309937e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.953889e+01</td>\n",
       "      <td>8.052808e+06</td>\n",
       "      <td>1.331901e+06</td>\n",
       "      <td>1.023963e+01</td>\n",
       "      <td>4.968409e-01</td>\n",
       "      <td>1.955620e-01</td>\n",
       "      <td>4.526754e-01</td>\n",
       "      <td>4.195258e+01</td>\n",
       "      <td>4.327172e+01</td>\n",
       "      <td>1.617517e-01</td>\n",
       "      <td>2.684495e-01</td>\n",
       "      <td>3.284109e-01</td>\n",
       "      <td>4.189721e-01</td>\n",
       "      <td>2.062878e+04</td>\n",
       "      <td>7.910031e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.220000e+04</td>\n",
       "      <td>2.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.210000e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>3.795400e+04</td>\n",
       "      <td>5.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.435795e+00</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>1.180000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>5.122700e+04</td>\n",
       "      <td>4.450000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.392452e+04</td>\n",
       "      <td>2.121764e+09</td>\n",
       "      <td>1.583454e+09</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration  source_bytes  destination_bytes         count  \\\n",
       "count  7.875764e+06  7.875764e+06       7.875764e+06  7.875764e+06   \n",
       "mean   1.317268e+00  5.492566e+04       2.175131e+03  5.175024e+00   \n",
       "std    7.953889e+01  8.052808e+06       1.331901e+06  1.023963e+01   \n",
       "min    0.000000e+00  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "50%    4.210000e-04  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "75%    1.435795e+00  6.500000e+01       1.180000e+02  4.000000e+00   \n",
       "max    8.392452e+04  2.121764e+09       1.583454e+09  1.000000e+02   \n",
       "\n",
       "       same_srv_rate   serror_rate  srv_serror_rate  dst_host_count  \\\n",
       "count   7.875764e+06  7.875764e+06     7.875764e+06    7.875764e+06   \n",
       "mean    4.744613e-01  4.152513e-02     4.192815e-01    3.506128e+01   \n",
       "std     4.968409e-01  1.955620e-01     4.526754e-01    4.195258e+01   \n",
       "min     0.000000e+00  0.000000e+00     0.000000e+00    0.000000e+00   \n",
       "25%     0.000000e+00  0.000000e+00     0.000000e+00    0.000000e+00   \n",
       "50%     0.000000e+00  0.000000e+00     3.000000e-02    1.100000e+01   \n",
       "75%     1.000000e+00  0.000000e+00     1.000000e+00    9.200000e+01   \n",
       "max     1.000000e+00  1.000000e+00     1.000000e+00    1.000000e+02   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_src_port_rate  dst_host_serror_rate  \\\n",
       "count        7.875764e+06                 7.875764e+06          7.875764e+06   \n",
       "mean         4.014791e+01                 2.828774e-02          8.570371e-02   \n",
       "std          4.327172e+01                 1.617517e-01          2.684495e-01   \n",
       "min          0.000000e+00                 0.000000e+00          0.000000e+00   \n",
       "25%          0.000000e+00                 0.000000e+00          0.000000e+00   \n",
       "50%          1.600000e+01                 0.000000e+00          0.000000e+00   \n",
       "75%          9.600000e+01                 0.000000e+00          0.000000e+00   \n",
       "max          1.000000e+02                 1.000000e+00          1.000000e+00   \n",
       "\n",
       "       dst_host_srv_serror_rate         label  source_port_number  \\\n",
       "count              7.875764e+06  7.875764e+06        7.875764e+06   \n",
       "mean               1.340752e-01 -9.081160e-01        3.344987e+04   \n",
       "std                3.284109e-01  4.189721e-01        2.062878e+04   \n",
       "min                0.000000e+00 -2.000000e+00        0.000000e+00   \n",
       "25%                0.000000e+00 -1.000000e+00        1.220000e+04   \n",
       "50%                0.000000e+00 -1.000000e+00        3.795400e+04   \n",
       "75%                0.000000e+00 -1.000000e+00        5.122700e+04   \n",
       "max                1.000000e+00  1.000000e+00        6.553500e+04   \n",
       "\n",
       "       destination_port_number  \n",
       "count             7.875764e+06  \n",
       "mean              2.309937e+03  \n",
       "std               7.910031e+03  \n",
       "min               0.000000e+00  \n",
       "25%               2.300000e+01  \n",
       "50%               5.300000e+01  \n",
       "75%               4.450000e+02  \n",
       "max               6.553500e+04  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kyoto_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それぞれのフローが攻撃かどうかは \"label\" 列に入っている。\n",
    "\n",
    "1は正常な通信、その他は不正な通信であり、不正な通信はいくつかの種類(-1:known attack, -2:unknown attack)に分かれている。\n",
    "\n",
    "label の種類数やそれぞれの label の数を表示するには、値とその値を持つデータの数を出力する `value_counts()` メソッドを利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "-1    7513100\n",
       " 1     362107\n",
       "-2        557\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kyoto_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数値化できていないデータの削除\n",
    "データセットの中には、そのまま用いることは困難な（そのままでは距離を定義することができない）データがある。\n",
    "例えば、protocol はプロトコルの種別が入っており、量ではないので、異なる種別間の距離は何らかの方法で定義する必要がある。\n",
    "そのため、学習を実行する前に、データに前処理を施す必要がある。\n",
    "\n",
    "今回は、そのようなデータを除いて学習を行う。学習に利用する列は以下とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_features = [\n",
    "    \"duration\", \"source_bytes\", \"destination_bytes\", \n",
    " \"count\", \"same_srv_rate\", \"serror_rate\", \"srv_serror_rate\",\"dst_host_count\",\n",
    "  \"dst_host_srv_count\", \"dst_host_same_src_port_rate\", \"dst_host_serror_rate\",\n",
    "  \"dst_host_srv_serror_rate\", \"source_port_number\", \"destination_port_number\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この列のみを抽出する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data = kyoto_data[use_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それぞれの列の値が取り得る値域は大きく異なるため、値域の幅が大きいものに結果が大きく影響してしまう可能性がある。そこで、`sklearn.preprocessing.MinMaxScaler` を利用し、最小値を0、最大値を1に正規化する。\n",
    "\n",
    "具体的には、MinMaxScaler の `fit_transform` メソッドを利用する。\n",
    "\n",
    "この返り値は numpy の array なので、Pandas で扱うには Pandas の DataFrame に戻す必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data = pandas.DataFrame(MinMaxScaler().fit_transform(use_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe メソッドで最小値が0, 最大値が1になっていることが確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "      <td>7.875764e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.569586e-05</td>\n",
       "      <td>2.588679e-05</td>\n",
       "      <td>1.373662e-06</td>\n",
       "      <td>5.175024e-02</td>\n",
       "      <td>4.744610e-01</td>\n",
       "      <td>4.152513e-02</td>\n",
       "      <td>4.192817e-01</td>\n",
       "      <td>3.506128e-01</td>\n",
       "      <td>4.014791e-01</td>\n",
       "      <td>2.828774e-02</td>\n",
       "      <td>8.570375e-02</td>\n",
       "      <td>1.340752e-01</td>\n",
       "      <td>5.104123e-01</td>\n",
       "      <td>3.524738e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.477432e-04</td>\n",
       "      <td>3.795336e-03</td>\n",
       "      <td>8.411361e-04</td>\n",
       "      <td>1.023963e-01</td>\n",
       "      <td>4.968409e-01</td>\n",
       "      <td>1.955620e-01</td>\n",
       "      <td>4.526754e-01</td>\n",
       "      <td>4.195258e-01</td>\n",
       "      <td>4.327172e-01</td>\n",
       "      <td>1.617517e-01</td>\n",
       "      <td>2.684495e-01</td>\n",
       "      <td>3.284109e-01</td>\n",
       "      <td>3.147750e-01</td>\n",
       "      <td>1.206993e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.861601e-01</td>\n",
       "      <td>3.509575e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.016413e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>1.100000e-01</td>\n",
       "      <td>1.600000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.791409e-01</td>\n",
       "      <td>8.087282e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.710817e-05</td>\n",
       "      <td>3.063489e-08</td>\n",
       "      <td>7.452062e-08</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.200000e-01</td>\n",
       "      <td>9.600000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.816739e-01</td>\n",
       "      <td>6.790265e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06   \n",
       "mean   1.569586e-05  2.588679e-05  1.373662e-06  5.175024e-02  4.744610e-01   \n",
       "std    9.477432e-04  3.795336e-03  8.411361e-04  1.023963e-01  4.968409e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    5.016413e-09  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    1.710817e-05  3.063489e-08  7.452062e-08  4.000000e-02  1.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06   \n",
       "mean   4.152513e-02  4.192817e-01  3.506128e-01  4.014791e-01  2.828774e-02   \n",
       "std    1.955620e-01  4.526754e-01  4.195258e-01  4.327172e-01  1.617517e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  3.000000e-02  1.100000e-01  1.600000e-01  0.000000e+00   \n",
       "75%    0.000000e+00  1.000000e+00  9.200000e-01  9.600000e-01  0.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                 10            11            12            13  \n",
       "count  7.875764e+06  7.875764e+06  7.875764e+06  7.875764e+06  \n",
       "mean   8.570375e-02  1.340752e-01  5.104123e-01  3.524738e-02  \n",
       "std    2.684495e-01  3.284109e-01  3.147750e-01  1.206993e-01  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  1.861601e-01  3.509575e-04  \n",
       "50%    0.000000e+00  0.000000e+00  5.791409e-01  8.087282e-04  \n",
       "75%    0.000000e+00  0.000000e+00  7.816739e-01  6.790265e-03  \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMの適用と結果の確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回用いるSVMは教師あり学習である。そのため、データに対してラベルを与える必要がある。なお、攻撃か否かを判断する場合は -1:known attack と-2:unknown attack の区別は不要であるため、\"-2\"を\"-1\"に置換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = kyoto_data['label']\n",
    "label_data = label_data.replace(-2, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータに対して、SVM を実行する。ここでは例としてrbfカーネル`'rbf'`を指定している。テストデータを全て使用するとかなりの時間がかかるため、ここでは先頭から100000個のみを用いて検証している。\n",
    "\n",
    "学習には10分程度要する。 ただし、演習の本筋ではないため、実行はスキップして良い。実行結果の例はコメントで用意している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         -1\n",
      "1         -1\n",
      "2         -1\n",
      "3         -1\n",
      "4         -1\n",
      "          ..\n",
      "7875759   -1\n",
      "7875760   -1\n",
      "7875761   -1\n",
      "7875762   -1\n",
      "7875763   -1\n",
      "Name: label, Length: 7875764, dtype: int8\n"
     ]
    }
   ],
   "source": [
    "print(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(gamma='auto')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# 線形SVMのインスタンスを生成\n",
    "model = SVC(kernel='rbf', gamma='auto', random_state=None)\n",
    "\n",
    "# 学習するデータの数\n",
    "learn_amounts = 100000\n",
    "\n",
    "# モデルの学習。fit関数で行う。\n",
    "model.fit(use_data[:learn_amounts], label_data[:learn_amounts])\n",
    "\n",
    "# Output\n",
    "# SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#     decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "#     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#     tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が完了したら、訓練データそのものに対する精度を確認する。\n",
    "\n",
    "学習をスキップした場合は、このプログラムもスキップすること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データに対する正解率： 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 訓練データに対する精度\n",
    "pred_train = model.predict(use_data[:learn_amounts])\n",
    "accuracy_train = accuracy_score(label_data[:learn_amounts], pred_train[:learn_amounts])\n",
    "print('訓練データに対する正解率： %.2f' % accuracy_train)\n",
    "\n",
    "# Output\n",
    "# 訓練データに対する正解率： 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上のように、訓練データに対して、そこそこ高い正解率が得られていると言える。しかし、データの分類を見て見ると、\n",
    "\n",
    "(こちらも、学習をスキップした場合はプログラムの実行をスキップすること)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: normal.\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "predict: attack.\n",
      "label\n",
      "-1    96794\n",
      " 1     3206\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_kinds = [1, -1]\n",
    "label_dict = {1:'normal.', -1:'attack.'}\n",
    "\n",
    "# 予測値ごとに学習データを類別する\n",
    "label_names = [label_data[:learn_amounts][pred_train==x] for x in label_kinds]\n",
    "for idx, val in enumerate(label_kinds):\n",
    "    print(\"predict: {}\".format(label_dict[val]))\n",
    "    print(label_names[idx].value_counts())\n",
    "    print()\n",
    "    \n",
    "# Output\n",
    "# predict: normal.\n",
    "# Series([], Name: label, dtype: int64)\n",
    "# \n",
    "# predict: attack.\n",
    "# -1    96794\n",
    "#  1     3206\n",
    "# Name: label, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ほぼ全てのデータを\"attack\"だと判断していることが分かる。そもそも本来\"normal\"に分類すべきデータ数が全体の数%しかないのだから、全て\"attack\"とみなしても、これだけの精度が得られたように見えるのである。\n",
    "しかし、このような分類では現実においては何の役にも立たないため、改良が必要である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不均衡データへの対策\n",
    "今回の例のように訓練データの数に偏りがある場合、全てのデータが一方に分類されるという恐れがある。その対策にはいくつかの方法があるが、ここでは使うデータ数を少ない方に合わせる「Under Sampling」を適用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       " 1    45263\n",
       "-1    45263\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labelを学習用データuse_dataと統合する\n",
    "use_data['label'] = label_data\n",
    "\n",
    "# labelの値で類別する\n",
    "normal_data = use_data[use_data.label == 1]\n",
    "attack_data = use_data[use_data.label == -1]\n",
    "\n",
    "# ランダムにサンプリングする(random_state=0より実行毎に値が変わることはない)\n",
    "sample_amounts = int(len(normal_data)/8)\n",
    "attack_data_sampled = attack_data.sample(n=sample_amounts, random_state=0)\n",
    "normal_data_sampled = normal_data.sample(n=sample_amounts, random_state=0)\n",
    "\n",
    "# 統合する\n",
    "use_data_sampled = pandas.concat([normal_data_sampled,attack_data_sampled])\n",
    "\n",
    "# 数の確認\n",
    "print(['label'])\n",
    "use_data_sampled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こうすることで、データ数を合わせることができる。\n",
    "このデータに対して再度SVMを用いて学習を行う。\n",
    "\n",
    "学習には10分程度要する。一つ前の学習と同様に演習の本筋ではないため、プログラムの実行をスキップしても良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(gamma='auto')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# 線形SVMのインスタンスを生成\n",
    "model = SVC(kernel='rbf', gamma='auto', random_state=None)\n",
    "\n",
    "# モデルの学習。fit関数で行う。\n",
    "model.fit(use_data_sampled.drop('label', axis=1), use_data_sampled['label'])\n",
    "\n",
    "# Output\n",
    "# SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#     decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "#     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#     tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果の確認\n",
    "学習が完了したら、まずは訓練データそのものに対する精度を確認する。\n",
    "\n",
    "学習をスキップした場合は、このプログラムの実行もスキップすること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データに対する正解率： 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 訓練データに対する精度\n",
    "pred_train = model.predict(use_data_sampled.drop('label', axis=1))\n",
    "accuracy_train = accuracy_score(use_data_sampled['label'], pred_train)\n",
    "print('訓練データに対する正解率： %.2f' % accuracy_train)\n",
    "\n",
    "# Output\n",
    "# 訓練データに対する正解率： 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いてデータの分類を確認する。\n",
    "\n",
    "こちらも、学習をスキップした場合は、実行をスキップすること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: normal.\n",
      "label\n",
      " 1    41446\n",
      "-1    14176\n",
      "Name: count, dtype: int64\n",
      "\n",
      "predict: attack.\n",
      "label\n",
      "-1    31087\n",
      " 1     3817\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_kinds = [1, -1]\n",
    "label_dict = {1:'normal.', -1:'attack.'}\n",
    "\n",
    "label_data_sampled = use_data_sampled['label']\n",
    "\n",
    "label_names = [label_data_sampled.iloc[pred_train==x] for x in label_kinds]\n",
    "for idx, val in enumerate(label_kinds):\n",
    "    print(\"predict: {}\".format(label_dict[val]))\n",
    "    print(label_names[idx].value_counts())\n",
    "    print()\n",
    "    \n",
    "# Output\n",
    "# predict: normal.\n",
    "#  1    41446\n",
    "# -1    14176\n",
    "# Name: label, dtype: int64\n",
    "\n",
    "# predict: attack.\n",
    "# -1    31087\n",
    "#  1     3817\n",
    "# Name: label, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検証\n",
    "本演習の目的は、あるフローが与えられた時に正規の通信か不正な通信かを予測する予測モデルを過去のトラフィックデータから生成することである。\n",
    "\n",
    "ここでは、過去の通信から現在の通信が正規なものか不正なものかを判断するので、時間的な順序を考慮し、データセットを分割し、過去のトラフィックデータで学習させたもので新しい通信の予測がどの程度正しいかどうかの検証を行う。\n",
    "\n",
    "まずはデータセットのラベルを attack と normal の2種類に変換する関数を用意する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(label):\n",
    "    if label == 1:\n",
    "        ret = 'normal.'\n",
    "    else:\n",
    "        ret = 'attack.'\n",
    "    return ret\n",
    "label_dict = {1:'normal.', -1:'attack.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを4分割し、過去の3セットで学習し、それより新しい1セットの予測を検証する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = int(len(use_data)/4)\n",
    "learn_data = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習に利用するデータセットを準備する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data_part = use_data[0:data_len * learn_data]\n",
    "\n",
    "# labelの値で分離する\n",
    "normal_data = use_data_part[use_data_part.label == 1]\n",
    "attack_data = use_data_part[use_data_part.label == -1]\n",
    "\n",
    "# ランダムにサンプリングする(random_state=0より実行毎に値が変わることはない)\n",
    "sample_amounts = int(len(normal_data)/6)\n",
    "attack_data_sampled = attack_data.sample(n=sample_amounts, random_state=0)\n",
    "normal_data_sampled = normal_data.sample(n=sample_amounts, random_state=0)\n",
    "\n",
    "# 統合する\n",
    "use_data_sampled = pandas.concat([normal_data_sampled,attack_data_sampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMで学習させ、予測を行う。ただし演習の説明では時間短縮のため、学習に用いていなかったデータ全ての予測は行わない。例として、学習に用いていなかったデータの5%だけを予測対象として扱うこととする。\n",
    "\n",
    "学習と予測には10分程度要する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "model2 = SVC(kernel='rbf', gamma='auto', random_state=None)\n",
    "\n",
    "# モデルの学習。fit関数で行う。\n",
    "model2.fit(use_data_sampled.drop('label', axis=1), use_data_sampled['label'])\n",
    "# 学習に用いなかったデータの予測を行う。\n",
    "start = data_len * learn_data # このインデックスまで学習に用いている\n",
    "length = int((len(use_data)-start)/20) # 予測用データのうち5%だけ、予測対象とする\n",
    "pred = model.predict(use_data.drop('label', axis=1)[start: start + length]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測が正しいかどうかを検証する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success = 85302, failed = 13145, normal = 2883, attack = 95564, unknown = 0\n",
      "TP = 2549, FN = 334, FP = 12811, TN = 82753\n"
     ]
    }
   ],
   "source": [
    "success = 0\n",
    "fail = 0\n",
    "normal = 0\n",
    "attack = 0\n",
    "# correct_predict\n",
    "tp = 0 # 真陽性(true positive) ：　正しく陽性と判定\n",
    "fn = 0 # 偽陰性(false negative)　：　本当は陽性なのに、陰性と判定\n",
    "fp = 0 #偽陽性(false positive)　：　本当は陰性なのに、陽性と判定\n",
    "tn = 0 #真陰性(true negative)　：　正しく陰性と判定\n",
    "    \n",
    "for i in range(length):\n",
    "    predicate = label_dict[pred[i]]\n",
    "    correct = get_label(kyoto_data['label'][data_len * learn_data + i])\n",
    "    if predicate == correct:\n",
    "        # 正常通信と攻撃通信の数を計算\n",
    "        success += 1\n",
    "        # 真陽性か真陰性か\n",
    "        if correct == 'normal.':\n",
    "            tp += 1\n",
    "        elif correct == 'attack.':\n",
    "            tn += 1\n",
    "    else:\n",
    "        fail += 1\n",
    "        # 偽陰性か偽陽性か\n",
    "        if correct == 'normal.':\n",
    "            fn += 1\n",
    "        elif correct == 'attack.':\n",
    "            fp += 1\n",
    "    # 正常通信と攻撃通信の数を計算\n",
    "    if correct == 'normal.':\n",
    "        normal += 1\n",
    "    elif correct == 'attack.':\n",
    "        attack += 1\n",
    "print(\"success = {}, failed = {}, normal = {}, attack = {}, unknown = {}\".format(success, fail, normal, attack, success + fail - normal - attack))\n",
    "print(\"TP = {}, FN = {}, FP = {}, TN = {}\".format(tp, fn, fp, tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、予測が正しいかの検証は以下のプログラムを実行しても確認できる。混同行列と呼ばれる2×2行列の各成分を見ることで、TPの値などを調べられる。\n",
    "混合行列である`confusion_matrix`から各成分の値を取り出す際は、`ravel()`メソッドを用いれば良い。\n",
    "\n",
    "\n",
    "$$\n",
    "    ConfusionMatrix = \\left[\\begin{array}{c|c} TN & FP \\\\ \\hline FN & TP \\\\ \\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82753 12811]\n",
      " [  334  2549]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predicate = pred\n",
    "correct = label_data[start:start+ length]\n",
    "\n",
    "c_matrix = confusion_matrix(correct, predicate)\n",
    "tn, fp, fn, tp = c_matrix.ravel()\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類問題のモデルを評価する際に使われる代表的な評価指標\n",
    "1. 正確度(Accuracy): 推定した値と真の値が一致した割合\n",
    "$$ \\frac{TP + TN}{TP + FP + TN + FN} = \\frac{正しく判定}{全体}$$\n",
    "    - FPとFNの重要度について考慮しなくていい場合に使える\n",
    "2. 適合率(Precision): モデルが陽性と判定した中で、真に陽性だった割合 \n",
    "$$ \\frac{TP}{TP + FP} = \\frac{真に陽性}{陽性と判定} $$\n",
    "    - 明らかに陽性と分かりやすいものだけを見つけたい時\n",
    "    - FNが発生することを許容できるようなケースで、それでもなおFPがあっては困る場合に使える\n",
    "3. 再現率(Recall): 真に陽性だったものの中で、モデルが陽性と判定した割合 \n",
    "$$ \\frac{TP}{TP + FN} = \\frac{陽性と判定}{真に陽性} $$\n",
    "    - 怪しいものを全て見つけ出したい時\n",
    "    - FPが発生することを許容できるケースで、それでもなおFNがあっては困る場合に使える。\n",
    "4. F-値(F-measure): 適合率と再現率の調和平均\n",
    "$$ \\frac{2}{\\frac{1}{Precision} + \\frac{1}{Recall}} =  \\frac{2 * (Precision * Recall)}{Precision + Recall} $$\n",
    "    - 正確度と違い、陽性と陰性の出現度合いが極端に異なる場合でも、評価しやすい\n",
    "5. 特異度(Specificity): 実際に陰性だったものの中で、モデルが陽性と判断した割合\n",
    "$$ \\frac{TN}{FP + TN} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8664763781527116\n",
      "Precision = 0.16595052083333334\n",
      "Recall = 0.8841484564689559\n",
      "F-measure = 0.2794496519212849\n",
      "Specificity = 0.8659432422251057\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = {}\" .format((tp + tn) / (tp + tn + fp + fn) ))\n",
    "if tp > 0 or fp > 0:\n",
    "    print(\"Precision = {}\" .format( tp/ (tp + fp) ))\n",
    "print(\"Recall = {}\" .format(tp/ (tp + fn) ))\n",
    "print(\"F-measure = {}\" .format(2 * tp / (2 * tp + fn + fp ) ))\n",
    "print(\"Specificity = {}\" .format(tn/(fp + tn) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際には、学習および検証に使うデータの時期を少しずつ変更して何度も評価が行われる。\n",
    "例えば、利用するデータセットを n 週間分 (n = 1,...) ずらして同様の評価を行うなどが考えられる。\n",
    "\n",
    "演習の手順説明では`sklearn.svm.SVC`を用いた。このモデルには他にもカーネル関数として `poly` などが用意されている。詳細は http://scikit-learn.org/stable/modules/svm.html#svm-kernels を参照すること。\n",
    "\n",
    "また、今回のデータセットは量が多いため線形SVMを使うことも考えられる。この場合は学習前にデータセットを近似することで効率を上げることができる。\n",
    "> For large datasets consider using sklearn.linear_model.LinearSVC or sklearn.linear_model.SGDClassifier instead, possibly after a sklearn.kernel_approximation.Nystroem transformer.\n",
    "\n",
    "引用: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
